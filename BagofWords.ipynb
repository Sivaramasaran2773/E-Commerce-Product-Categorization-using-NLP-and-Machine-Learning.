{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPJNcWyG-42Q",
        "outputId": "20c65ac9-eee2-47c9-a9ff-6e311348f7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bag of words saved to 'bag_of_words.txt'\n",
            "+------------------------+------------+-------------+----------+------------+\n",
            "| Model                  |   Accuracy |   Precision |   Recall |   F1 Score |\n",
            "+========================+============+=============+==========+============+\n",
            "| SVC                    |   0.931127 |    0.9298   | 0.930463 |   0.930127 |\n",
            "+------------------------+------------+-------------+----------+------------+\n",
            "| LGBMClassifier         |   0.9385   |    0.940254 | 0.937095 |   0.938577 |\n",
            "+------------------------+------------+-------------+----------+------------+\n",
            "| KNeighborsClassifier   |   0.802014 |    0.837442 | 0.814549 |   0.810083 |\n",
            "+------------------------+------------+-------------+----------+------------+\n",
            "| RandomForestClassifier |   0.933465 |    0.938668 | 0.930016 |   0.933902 |\n",
            "+------------------------+------------+-------------+----------+------------+\n",
            "| XGBClassifier          |   0.927711 |    0.931439 | 0.924988 |   0.927944 |\n",
            "+------------------------+------------+-------------+----------+------------+\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Define preprocessing function\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        # Convert text to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove punctuation and special characters\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        return text\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# Function to create bag of words\n",
        "def create_bag_of_words(csv_file):\n",
        "    bag_of_words = defaultdict(int)\n",
        "    with open(csv_file, 'r', newline='', encoding='utf-8') as file:\n",
        "        reader = csv.reader(file)\n",
        "        next(reader, None)  # Skip header\n",
        "        for row in reader:\n",
        "            text = row[0]  # Assuming the text is in the first column\n",
        "            text = preprocess_text(text)\n",
        "            words = text.split()\n",
        "            for word in words:\n",
        "                bag_of_words[word] += 1\n",
        "    return bag_of_words\n",
        "\n",
        "# Function to save bag of words to a file\n",
        "def save_bag_of_words(bag_of_words, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for word, count in bag_of_words.items():\n",
        "            file.write(f'{word}: {count}\\n')\n",
        "\n",
        "# Suppress LightGBM messages\n",
        "class SuppressedOutput:\n",
        "    def __enter__(self):\n",
        "        self.devnull = open(os.devnull, 'w')\n",
        "        self.stdout_orig = sys.stdout\n",
        "        self.stderr_orig = sys.stderr\n",
        "        sys.stdout = self.devnull\n",
        "        sys.stderr = self.devnull\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout = self.stdout_orig\n",
        "        sys.stderr = self.stderr_orig\n",
        "        self.devnull.close()\n",
        "\n",
        "# Load dataset\n",
        "csv_file = \"/content/ecommerceDataset_normalized.csv\"\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Apply text preprocessing\n",
        "df['text_preprocessed'] = df['normalized description'].apply(preprocess_text)\n",
        "\n",
        "# Generate bag of words\n",
        "bag_of_words = create_bag_of_words(csv_file)\n",
        "\n",
        "# Save bag of words to a file\n",
        "save_bag_of_words(bag_of_words, \"bag_of_words.txt\")\n",
        "print(\"Bag of words saved to 'bag_of_words.txt'\")\n",
        "\n",
        "# Convert bag of words to feature vectors using CountVectorizer\n",
        "vectorizer = CountVectorizer(vocabulary=bag_of_words.keys())\n",
        "X = vectorizer.fit_transform(df['text_preprocessed'])\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models\n",
        "models = [\n",
        "    SVC(kernel='linear'),\n",
        "    LGBMClassifier(),\n",
        "    KNeighborsClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    XGBClassifier()\n",
        "]\n",
        "# Convert input data to np.float32\n",
        "X_train = X_train.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)\n",
        "\n",
        "from tabulate import tabulate\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "# Initialize an empty list to store the results\n",
        "results = []\n",
        "# Train and evaluate each model\n",
        "for model in models:\n",
        "    with SuppressedOutput():\n",
        "        model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
        "    precision = report['macro avg']['precision']\n",
        "    recall = report['macro avg']['recall']\n",
        "    f1_score = report['macro avg']['f1-score']\n",
        "    results.append([type(model).__name__, accuracy, precision, recall, f1_score])\n",
        "\n",
        "# Print results as a table\n",
        "headers = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
        "print(tabulate(results, headers=headers, tablefmt=\"grid\"))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
